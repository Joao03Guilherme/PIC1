\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{nil}{}
\citation{Neifeld1993}
\citation{Foor1995}
\citation{Psaltis1984}
\citation{Dragulinescu2023}
\citation{VanderLugt1964}
\citation{Cruzeiro2024}
\citation{Sergioli2025}
\citation{Neifeld1993}
\citation{Foor1995}
\citation{Javidi1989}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Theory}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {i}Machine learning and supervised learning}{1}{subsection.2.1}\protected@file@percent }
\newlabel{subsec:ml}{{i}{1}{Machine learning and supervised learning}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Input data.}{1}{paragraph*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Training and test sets.}{1}{paragraph*.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces One representative example per class from the MNIST dataset. Each \(28\times 28\) grayscale image is flattened to a \(p=784\)-dimensional feature vector before the pre-processing pipeline (centering, standardisation, PCA).\relax }}{1}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:mnist-examples}{{1}{1}{One representative example per class from the MNIST dataset. Each \(28\times 28\) grayscale image is flattened to a \(p=784\)-dimensional feature vector before the pre-processing pipeline (centering, standardisation, PCA).\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Pre-processing.}{1}{paragraph*.4}\protected@file@percent }
\citation{Sergioli2025}
\citation{Sergioli2025}
\@writefile{toc}{\contentsline {paragraph}{Balanced accuracy.}{2}{paragraph*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Classical Nearest-Mean Classifier (CNM-C).}{2}{paragraph*.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Ilustration of the CNM-C decision rule. The training set is split into two classes and the centroids are computed. The nearest centroid to the test sample is selected as the predicted class.\relax }}{2}{figure.caption.7}\protected@file@percent }
\newlabel{fig:nearest_mean_classifier}{{2}{2}{Ilustration of the CNM-C decision rule. The training set is split into two classes and the centroids are computed. The nearest centroid to the test sample is selected as the predicted class.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {ii}Quantum-inspired classification}{2}{subsection.2.2}\protected@file@percent }
\newlabel{subsec:qic}{{ii}{2}{Quantum-inspired classification}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Density--pattern encodings.}{2}{paragraph*.8}\protected@file@percent }
\newlabel{par:encodings}{{ii}{2}{Density--pattern encodings}{paragraph*.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Quantum centroid.}{2}{paragraph*.9}\protected@file@percent }
\citation{Javidi1989}
\@writefile{toc}{\contentsline {paragraph}{Quantum distance measure.}{3}{paragraph*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Quantum-inspired nearest-mean classifier (QNM-C).}{3}{paragraph*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {iii}Joint Transform Correlator}{3}{subsection.2.3}\protected@file@percent }
\newlabel{subsec:jtc}{{iii}{3}{Joint Transform Correlator}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Operational principle.}{3}{paragraph*.12}\protected@file@percent }
\newlabel{fig:corr-shifted}{{3a}{3}{Original image vs.\ shifted copy\relax }{figure.caption.13}{}}
\newlabel{sub@fig:corr-shifted}{{a}{3}{Original image vs.\ shifted copy\relax }{figure.caption.13}{}}
\newlabel{fig:corr-random}{{3b}{3}{Original image vs.\ random image\relax }{figure.caption.13}{}}
\newlabel{sub@fig:corr-random}{{b}{3}{Original image vs.\ random image\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Correlation-plane intensity produced by the joint transform correlator: (a) shows two strong off-axis peaks because the query is a shifted version of the reference, whereas (b) shows no significant peaks for an unrelated image.\relax }}{3}{figure.caption.13}\protected@file@percent }
\newlabel{fig:jtc-diagram}{{3}{3}{Correlation-plane intensity produced by the joint transform correlator: (a) shows two strong off-axis peaks because the query is a shifted version of the reference, whereas (b) shows no significant peaks for an unrelated image.\relax }{figure.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Classification accuracy (mean $\pm $ std.)\relax }}{4}{table.caption.14}\protected@file@percent }
\newlabel{tab:cls-results}{{1}{4}{Classification accuracy (mean $\pm $ std.)\relax }{table.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {iv}Optical implementation of the QNM-C}{4}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Results}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Data Encoding}{4}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {i}Gram Matrix Encoding}{4}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Gram matrix encoding $\rho $ of the digit 1 image\relax }}{4}{figure.caption.15}\protected@file@percent }
\newlabel{fig:density_matrix}{{4}{4}{Gram matrix encoding $\rho $ of the digit 1 image\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Radial Basis Function Network}{4}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {i}Exact Interpolation}{4}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {ii}Classification}{4}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {iii}Training with Least Squares}{4}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VI}Choosing RBF Centers}{4}{section.6}\protected@file@percent }
\bibdata{references}
\bibcite{Cruzeiro2024}{1}
\bibcite{Dragulinescu2023}{2}
\bibcite{Foor1995}{3}
\bibcite{Javidi1989}{4}
\bibcite{Neifeld1993}{5}
\bibcite{Psaltis1984}{6}
\bibcite{Sergioli2025}{7}
\bibcite{VanderLugt1964}{8}
\bibstyle{plain}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Example of a Gaussian RBF centered at $\mu $\relax }}{5}{figure.caption.16}\protected@file@percent }
\newlabel{fig:gaussian_rbf}{{5}{5}{Example of a Gaussian RBF centered at $\mu $\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Implementation Notes}{5}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Optical Im}{5}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IX}Conclusion}{5}{section.9}\protected@file@percent }
\gdef \@abspage@last{6}
